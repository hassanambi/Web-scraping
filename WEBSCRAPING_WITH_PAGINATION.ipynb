{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMtNQLMWiSFo0oKCOHpkfo8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hassanambi/Web-scraping/blob/main/WEBSCRAPING_WITH_PAGINATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LIBRARY INSTALLATIONS"
      ],
      "metadata": {
        "id": "u6Cyh3fjkHgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4VH06DAuIlE",
        "outputId": "c7b4f866-f9b5-4242-e445-638d9ca71e99"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "W4xL4E7dL2jE"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WEBPAGE INITIALIZATION"
      ],
      "metadata": {
        "id": "tcgO2LgykbF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = 'https://books.toscrape.com/catalogue/page-{}.html'\n",
        "\n",
        "page_number = 1\n",
        "product_details = []"
      ],
      "metadata": {
        "id": "hc_-zABjZgw6"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PAGINATION AND DATA EXTRACTION FOR EACH PAGE"
      ],
      "metadata": {
        "id": "7NlDzrP9koY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    url = base_url.format(page_number)\n",
        "    print(f\"Scraping page {page_number}...\")\n",
        "\n",
        "    # Fetch the page content\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.text, 'html')\n",
        "\n",
        "    # Print the title of the page for confirmation\n",
        "    print(soup.title.text)\n",
        "\n",
        "    # Find all product listings on the page\n",
        "    product_list = soup.find_all('li', class_='col-xs-6 col-sm-4 col-md-3 col-lg-3')\n",
        "\n",
        "    # If no products are found, break the loop (end of pagination)\n",
        "    if not product_list:\n",
        "        print(f\"No products found on page {page_number}. Exiting the loop.\")\n",
        "        break\n",
        "\n",
        "    # Extract product details\n",
        "    for product in product_list:\n",
        "        # Extract product title\n",
        "        h3_tag = product.find('h3')\n",
        "        if h3_tag:\n",
        "            product_title = h3_tag.find('a').get('title')\n",
        "        else:\n",
        "            product_title = 'No Title Found'\n",
        "\n",
        "        # Extract product price\n",
        "        price_tag = product.find('p', class_='price_color')\n",
        "        if price_tag:\n",
        "            product_price = price_tag.text.replace('Â', '').strip()  # Clean up encoding issues\n",
        "        else:\n",
        "            product_price = 'No Price Found'\n",
        "\n",
        "        # Extract product rating\n",
        "        rating_tag = product.find('p', class_='star-rating')\n",
        "        if rating_tag:\n",
        "            # Extract the rating class (e.g., \"star-rating Three\")\n",
        "            rating_classes = rating_tag.get('class', [])\n",
        "            rating_mapping = {\n",
        "                'One': 1,\n",
        "                'Two': 2,\n",
        "                'Three': 3,\n",
        "                'Four': 4,\n",
        "                'Five': 5\n",
        "            }\n",
        "            if len(rating_classes) > 1 and rating_classes[1] in rating_mapping:\n",
        "                product_rating = rating_mapping[rating_classes[1]]  # Convert to numerical rating\n",
        "            else:\n",
        "                product_rating = 'No Rating Found'\n",
        "        else:\n",
        "            product_rating = 'No Rating Found'\n",
        "\n",
        "        # Extract product availability\n",
        "        product_availability_tag = product.find('p', class_='instock availability')\n",
        "        if product_availability_tag:\n",
        "            product_availability = product_availability_tag.get_text(strip=True)  # Strip extra whitespace\n",
        "        else:\n",
        "            product_availability = 'Not Available'\n",
        "\n",
        "        # Add the details to the list\n",
        "        product_details.append((product_title, product_price, product_rating, product_availability))\n",
        "\n",
        "    # Increment to move to the next page\n",
        "    page_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_xAo41BaigI",
        "outputId": "dfe68c3f-d738-4c41-922d-1fe7d429b4e3"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 2...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 3...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 4...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 5...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 6...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 7...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 8...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 9...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 10...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 11...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 12...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 13...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 14...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 15...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 16...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 17...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 18...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 19...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 20...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 21...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 22...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 23...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 24...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 25...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 26...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 27...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 28...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 29...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 30...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 31...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 32...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 33...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 34...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 35...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 36...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 37...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 38...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 39...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 40...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 41...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 42...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 43...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 44...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 45...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 46...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 47...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 48...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 49...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 50...\n",
            "\n",
            "    All products | Books to Scrape - Sandbox\n",
            "\n",
            "Scraping page 51...\n",
            "404 Not Found\n",
            "No products found on page 51. Exiting the loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA STORAGE"
      ],
      "metadata": {
        "id": "T3XWaxRMkytk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from the extracted details\n",
        "data = pd.DataFrame(product_details, columns=['Title', 'Price', 'Rating', 'Availability'])\n",
        "\n",
        "# Save to a CSV file\n",
        "data.to_csv('books_to_scrape.csv', index=False)\n",
        "print(\"Data saved to books_to_scrape.csv\")\n",
        "\n",
        "# Print the first few rows of the DataFrame\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQBLhlN-frgM",
        "outputId": "2977f691-d9f8-47af-f058-ce4123684a8f"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to books_to_scrape.csv\n",
            "                                   Title   Price  Rating Availability\n",
            "0                   A Light in the Attic  £51.77       3     In stock\n",
            "1                     Tipping the Velvet  £53.74       1     In stock\n",
            "2                             Soumission  £50.10       1     In stock\n",
            "3                          Sharp Objects  £47.82       4     In stock\n",
            "4  Sapiens: A Brief History of Humankind  £54.23       5     In stock\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ymrv8f5vjH2S"
      },
      "execution_count": 106,
      "outputs": []
    }
  ]
}